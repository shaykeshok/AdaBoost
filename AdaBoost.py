from itertools import combinations

import numpy as np
from numpy import random
from pandas import DataFrame

from Line import Line


class AdaBoost:

    def __init__(self, df, k, iterations):
        self.df = df
        self.k = k
        self.iterations = iterations

    def active(self):
        for k in range(1, self.k):
            e_ğ»_k_T = 0
            e_ğ»_k_S = 0
            for iterator in range(self.iterations):

                # create 2 random sets from the data: 1-train, 2-test
                random.shuffle(self.df)
                middle = int(self.df.size / 8)
                S = self.df[1:middle]  # Train
                T = self.df[middle + 1:]  # Test

                rules = self.run_adaboost_algo(S, k)

                for point in S:
                    ğ»_k = 0  # ğ»ğ‘˜(ğ‘¥) = ğ‘ ğ‘–ğ‘”ğ‘›(Î£ğ›¼ğ‘–â„ğ‘– (ğ‘¥))
                    for hyp, ğ›¼ in rules:
                        ğ»_k += ğ›¼ * hyp.point_labeling(point, hyp.c)
                    e_ğ»_k_S += int(ğ»_k * point[2] < 0)
                for point in T:
                    ğ»_k = 0  # ğ»ğ‘˜(ğ‘¥) = ğ‘ ğ‘–ğ‘”ğ‘›(Î£ğ›¼ğ‘–â„ğ‘– (ğ‘¥))
                    for hyp, ğ›¼ in rules:
                        ğ»_k += ğ›¼ * hyp.point_labeling(point, hyp.c)
                    e_ğ»_k_T += int(ğ»_k * point[2] < 0)

            S_avg = (e_ğ»_k_S / self.iterations) / middle
            T_avg = (e_ğ»_k_T / self.iterations) / middle

            print("\n----------------------- round-" + str(k) + " ------------------------------")
            print("\nAverage error (train):", "%.3f" % S_avg + "%")
            print("\nAverage error (test):", "%.3f" % T_avg + "%")

    def run_adaboost_algo(self, dataset, k):  # dataset:dataframe
        rules_response = []

        # Initialize point weights
        for point in dataset:
            point[3] = 1 / len(dataset)
        for it in range(k):
            ğ‘_ğ‘¡ = 0
            â„_ğ‘¡, ğœ–_ğ‘¡ = self.find_min_rules(dataset)

            # If ğœ–_ğ‘¡(â„_ğ‘¡) is close to Â½, weight of classifier is low
            # If ğœ–_ğ‘¡(â„_ğ‘¡) is bigger then Â½, weight of classifier is worst
            if ğœ–_ğ‘¡ > 0.5 or ğœ–_ğ‘¡ <= 0:
                break

            # Set classifier weight ğ›¼_ğ‘¡ based on its error
            ğ›¼_ğ‘¡ = 0.5 * np.log((1 - ğœ–_ğ‘¡) / ğœ–_ğ‘¡)  # np.log is ln

            # update point weights
            for point in dataset:
                point[3] = point[3] * np.exp(-ğ›¼_ğ‘¡ * â„_ğ‘¡.point_labeling(point, â„_ğ‘¡.c) * point[2])
                ğ‘_ğ‘¡ += point[3]

            # Normalize these weights
            for point in dataset:
                point[3] = point[3] / ğ‘_ğ‘¡

            rules_response.append((â„_ğ‘¡, ğ›¼_ğ‘¡))
        return rules_response

    # Select classifier with min weighted error
    def find_min_rules(self, points):
        all_points_combination = combinations(points, 2)

        empirical_error_sum = 1  # min sum of errors
        min_rule = None
        for one_combination in all_points_combination:
            temp_rule = Line(one_combination[0], one_combination[1])
            temp_sum = 0
            temp_right_side = 0
            temp_left_side = 0

            #  Because the line is bi-directional we check here two options of the line:
            #  1. when the line classificated the points on the right side as positive and the points on the left side as negetive
            #  2. when the line classificated the points on the left side as positive and the points on the right side as negetive
            for point in points:
                temp_right_side += point[3] * int(int(point[2]) != temp_rule.point_labeling(point, 1))
                temp_left_side += point[3] * int(int(point[2]) != temp_rule.point_labeling(point, -1))
            temp_sum = temp_right_side
            if temp_left_side < temp_right_side:
                temp_sum = temp_left_side
                temp_rule.c = -1
            if temp_sum < empirical_error_sum:
                empirical_error_sum = temp_sum
                min_rule = temp_rule

        return min_rule, empirical_error_sum
